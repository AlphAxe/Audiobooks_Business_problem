{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audiobooks_Business_problem_with_Machine_learning",
      "provenance": [],
      "authorship_tag": "ABX9TyPRs5r0QzWHLW3+Ahh+X5ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlphAxe/Audiobooks_Business_problem/blob/master/Audiobooks_Business_problem_with_Machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKlwXj3-pkeR",
        "colab_type": "text"
      },
      "source": [
        "**Import Package for Preprocessing of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iWhIPBmpjvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM7v-Oy6qAud",
        "colab_type": "text"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjiyQPLYpjs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = np.loadtxt('/content/Audiobooks_data.csv', delimiter= ',')\n",
        "unscaled_all_input = raw_data[:,1:-1]\n",
        "target_all = raw_data[:,-1]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyttYT60z88p",
        "colab_type": "text"
      },
      "source": [
        "**Balancing of Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ez3uVY0Xq0",
        "colab_type": "text"
      },
      "source": [
        "let's make the data in balanced state means, same number of samples for both target classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtTH_YMpjFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_targets_one = int(np.sum(target_all))\n",
        "targets_zero_count = 0\n",
        "indexs_to_remove = []\n",
        "for i in range (target_all.shape[0]):\n",
        "  if target_all [i] == 0:\n",
        "    targets_zero_count += 1\n",
        "    if targets_zero_count > num_targets_one:\n",
        "      indexs_to_remove.append(i)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxTXZxc1pbrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting excessive samples\n",
        "unscaled_inputs_equal_prior = np.delete(unscaled_all_input,indexs_to_remove, axis= 0)\n",
        "targets_equal_prior = np.delete(target_all, indexs_to_remove, axis = 0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I28BBQ402Y1H",
        "colab_type": "text"
      },
      "source": [
        "**Standardization of inputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhEzfog0O1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_prior)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bHpW7ot3HvF",
        "colab_type": "text"
      },
      "source": [
        "**Shuffle the input data for better training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEPEeZdm3Hbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffled_indexes = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indexes)\n",
        "\n",
        "shuffled_inputs = scaled_inputs[shuffled_indexes]\n",
        "shuffled_targets = targets_equal_prior[shuffled_indexes]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mazIciQF4O5o",
        "colab_type": "text"
      },
      "source": [
        "**Splitting the input dataset in Training, validation, and test targets in ratio 80, 10, 10 %**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RPaBNkV2ztA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_samples = shuffled_inputs.shape[0]\n",
        "train_samples_counts = int(0.8 * total_samples)\n",
        "valid_samples_counts = int(0.1 * total_samples)\n",
        "test_samples_counts = total_samples - train_samples_counts - valid_samples_counts\n",
        "\n",
        "train_inputs = shuffled_inputs[: train_samples_counts]\n",
        "train_targets = shuffled_targets [: train_samples_counts]\n",
        "\n",
        "valid_inputs = shuffled_inputs[train_samples_counts : train_samples_counts + valid_samples_counts]\n",
        "valid_targets = shuffled_targets[ train_samples_counts : train_samples_counts + valid_samples_counts]\n",
        "\n",
        "test_inputs = shuffled_inputs[train_samples_counts + valid_samples_counts :]\n",
        "test_targets = shuffled_targets[train_samples_counts + valid_samples_counts :]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjWzs9xZBy7f",
        "colab_type": "text"
      },
      "source": [
        "**To check: our data is balanced or not**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH2YXy0J21pT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6adc8a7d-5647-4de0-e482-d8d4a9b66b35"
      },
      "source": [
        "print(np.sum(train_targets), train_samples_counts, np.sum(train_targets/train_samples_counts))\n",
        "print(np.sum(valid_targets), valid_samples_counts, np.sum(valid_targets/valid_samples_counts))\n",
        "print(np.sum(test_targets), test_samples_counts, np.sum(test_targets/test_samples_counts))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1794.0 3579 0.5012573344509639\n",
            "213.0 447 0.4765100671140939\n",
            "230.0 448 0.513392857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-I0vMXGDwLl",
        "colab_type": "text"
      },
      "source": [
        "**Save all the datasets in .npz format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEsFyfAMDLnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez('audiobooks_data_train', inputs = train_inputs, targets = train_targets)\n",
        "np.savez('audiobooks_data_validation', inputs = valid_inputs, targets = valid_targets)\n",
        "np.savez('audiobooks_data_test', inputs = test_inputs, targets = test_targets)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LonXSx49WWN-",
        "colab_type": "text"
      },
      "source": [
        "**Loading the preprocessed data for modelling purpose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V2JMhrbWQat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing tensorflow package for further process\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "#loading training data\n",
        "training_data = np.load('/content/audiobooks_data_train.npz')\n",
        "validation_data = np.load('/content/audiobooks_data_validation.npz')\n",
        "testing_data = np.load ('/content/audiobooks_data_test.npz')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-R7HJYqFNfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_inputs = training_data['inputs'].astype(np.float)\n",
        "training_targets = training_data['targets'].astype(np.int)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFXtFnvhYjHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_inputs = validation_data['inputs'].astype(np.float)\n",
        "validation_targets = validation_data['targets'].astype(np.int)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuY12NT7b6Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_inputs = testing_data['inputs'].astype(np.float)\n",
        "testing_targets = testing_data['targets'].astype(np.int)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yFkYPu6cTyu",
        "colab_type": "text"
      },
      "source": [
        "**Configure Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnNXK2oxcRYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "hidden_layer_size = 50\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             \n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation= 'relu'),\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation= 'relu'),\n",
        "                             tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "#selecting optimizer and loss function for model\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6sJowpeD6Y",
        "colab_type": "text"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDZtnw4rd93p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "67c0157e-de53-48ab-87c1-5a294d6a1bfb"
      },
      "source": [
        "batch_size = 100\n",
        "max_epochs = 100\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 1)\n",
        "model.fit(training_inputs,training_targets, \n",
        "          batch_size = batch_size,\n",
        "          epochs = max_epochs,\n",
        "          callbacks = [early_stopping],\n",
        "          validation_data = (validation_inputs,validation_targets), verbose = 2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 - 0s - loss: 0.2053 - accuracy: 0.9206 - val_loss: 0.2156 - val_accuracy: 0.9239\n",
            "Epoch 2/100\n",
            "36/36 - 0s - loss: 0.2076 - accuracy: 0.9195 - val_loss: 0.2087 - val_accuracy: 0.9239\n",
            "Epoch 3/100\n",
            "36/36 - 0s - loss: 0.2080 - accuracy: 0.9204 - val_loss: 0.2300 - val_accuracy: 0.9239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe98d53bfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxQxQ6fw6-Yn",
        "colab_type": "text"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COrZ5NejghcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30813a62-70f6-4784-b345-2831d334f795"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(testing_inputs,testing_targets)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.9107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-bt_ge7jp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}